from fastapi import FastAPI, Depends, Query, Request, Body, HTTPException
from fastapi.responses import FileResponse
from starlette.responses import JSONResponse, RedirectResponse, HTMLResponse
from starlette.staticfiles import StaticFiles
import pandas as pd
import asyncio
from algorithm.user_NPTI import model_predict_proba
from bigkinds_crawling.scheduler import sch_start, result_queue
from bigkinds_crawling.sample import sample_crawling, get_sample
from logger import Logger
from typing import Optional
from bigkinds_crawling.news_raw import news_crawling, get_news_raw, search_article
from bigkinds_crawling.news_aggr_grouping import news_aggr, related_news
from sqlalchemy.orm import Session
from database import get_db
from db_index.db_npti_type import get_all_npti_type, get_npti_type_by_group, npti_type_response, NptiTypeTable
from db_index.db_npti_code import get_all_npti_codes, get_npti_code_by_code, npti_code_response, NptiCodeTable
from db_index.db_npti_question import get_all_npti_questions, get_npti_questions_by_axis, npti_question_response
from db_index.db_user_info import UserCreateRequest, insert_user, authenticate_user, deactivate_user, get_my_page_data, \
    UserInfo, verify_password, UserUpdate, hash_password, get_user_info
from db_index.db_user_npti import get_user_npti_info, finalize_score
from sqlalchemy import text
from starlette.middleware.sessions import SessionMiddleware
from elasticsearch import Elasticsearch, ConnectionError as ESConnectionError
from datetime import timedelta, datetime, timezone
from db_index.db_user_answers import insert_user_answers
from db_index.db_user_npti import insert_user_npti
import json
from elasticsearch_index.es_user_behavior import index_user_behavior, search_user_behavior
from db_index.db_user_npti import UserNPTITable, UserNPTIResponse
from elasticsearch_index.es_raw import ES_INDEX, search_news_condition
from db_index.db_articles_NPTI import ArticlesNPTI
import math
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware


app = FastAPI()
logger = Logger().get_logger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # í”„ë¡ íŠ¸ì—”ë“œ ì£¼ì†Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.mount("/view",StaticFiles(directory="view"), name="view")
app.add_middleware(
    SessionMiddleware,
    secret_key="npti-secret-key",
    # max_age=60 * 60 * 24, #1ì¼
    max_age=int(timedelta(minutes=60).total_seconds()),
    same_site="lax"         # ê¸°ë³¸ ë³´ì•ˆ ì˜µì…˜
)

@app.get("/")
def main():
    return FileResponse("view/html/main.html")


# ê°œë³„ ê¸°ì‚¬ í˜ì´ì§€ -----------------------------------------------------------------
@app.get("/article")
async def view_page():
    return FileResponse("view/html/view.html")

@app.get("/article/{news_id}")
async def get_article(news_id:str):
    news_info = search_article(news_id)
    related = related_news(news_info["title"], news_id, news_info["category"])
    news_info["related_news"] = related
    print(f"related : {related}")
    if news_info:
        return JSONResponse(content=news_info,  status_code=200)
    else:
        return JSONResponse(content=None, status_code=404)


# JSì˜ sendBeacon('/log/behavior') ê²½ë¡œì™€ ì¼ì¹˜ì‹œí‚´
@app.post("/log/behavior")
async def collect_behavior_log(request: Request):
    try:
        # 1. Body ë°ì´í„°ë¥¼ Dictionaryë¡œ ë³€í™˜ (await í•„ìˆ˜)
        data = await request.json()

        # 2. ë°ì´í„° í™•ì¸ (í„°ë¯¸ë„ ì¶œë ¥)
        # JSì—ì„œ ë³´ë‚¸ payload êµ¬ì¡°: { news_id, user_id, session_end_time, total_logs, logs }
        news_id = data.get("news_id")
        user_id = data.get("user_id")
        log_count = data.get("total_logs")
        raw_logs = data.get("logs", [])
        stored_time = datetime.now(timezone(timedelta(hours=9))).isoformat(timespec='seconds')

        processed_docs = []
        for log in raw_logs:
            # JS ë³€ìˆ˜ëª… -> ES ë§¤í•‘ ë³€ìˆ˜ëª… ë³€í™˜
            doc = {
                "user_id": user_id,
                "news_id": news_id,
                "MMF_X_inf": log.get("MMF_X", 0.0),  # JS: MMF_X -> ES: MMF_X_inf
                "MMF_Y_inf": log.get("MMF_Y", 0.0),  # JS: MMF_Y -> ES: MMF_Y_inf
                "MSF_Y_inf": log.get("MSF_Y", 0.0),  # JS: MSF_Y -> ES: MSF_Y_inf
                "mouseX": log.get("mouseX", 0.0),
                "mouseY": log.get("mouseY", 0.0),
                "timestamp": int(log.get("elapsedMs", 0)),
                "baseline": log.get("baseline", 0.0),
                "stored_time": stored_time
            }
            processed_docs.append(doc)

        # 4. [ì €ì¥] ES ì¸ë±ì‹±
        if processed_docs:
            count = index_user_behavior(processed_docs)
            print(f"[Log] User:{user_id} | News:{news_id} | {count} ê°œ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            return {"status": "ok", "message": f"{count}ê°œ ë¡œê·¸ ì €ì¥"}
        else:
            return {"status": "ok", "message": "ì €ì¥í•  ë¡œê·¸ ì—†ìŒ"}

    except Exception as e:
        print(f"[ì—ëŸ¬ ë°œìƒ] {e}")
        return {"status": "error", "message": str(e)}

# ê¸°ì‚¬ npti ë¶„ë¥˜ ì •ë‹µ ë°ì´í„° ìˆ˜ì§‘ ----------------------------------------------------
@app.get("/sample")
def sample(max_pages: int = 90):
    logger.info(f"API í˜¸ì¶œ: í¬ë¡¤ë§ ì‹œì‘ (ìµœëŒ€ {max_pages} í˜ì´ì§€)")
    try:
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ í˜¸ì¶œ
        result = sample_crawling(max_pages=max_pages)
        return {"status": "success","count": len(result),"data": result}
    except Exception as e:
        logger.error(f"API ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"status": "error", "message": str(e)}


@app.get("/sample_csv")
def sample_csv(q: Optional[str] = None):
    logger.info(f"ES ë°ì´í„° ìš”ì²­ ìˆ˜ì‹  (query: {q})")
    try:
        result = get_sample(q)
        if result is None:
            return {"status": "error", "message": "ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        return result
    except Exception as e:
        logger.error(f"API ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"status": "error", "message": str(e)}


@app.get("/news_raw")
def news_raw(max_pages: int = 5):
    logger.info(f"í¬ë¡¤ë§ ì‹œì‘: ìµœëŒ€ {max_pages} í˜ì´ì§€")
    try:
        # sample.pyì˜ crawling í•¨ìˆ˜ í˜¸ì¶œ
        result = news_crawling(max_pages=max_pages)
        return {"status": "success","count": len(result),"data": result}
    except Exception as e:
        logger.error(f"API ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"status": "error", "message": str(e)}

sch = sch_start()
@app.get("/scheduler_start") # scheduler ìˆ˜ë™ ì‹œì‘
async def scheduler_start():
    if not sch.running:
        sch.start()
        return {'msg': 'scheduler ì‹¤í–‰ ì‹œì‘!'}
    else:
        return {'msg': 'ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.'}

@app.get("/news_aggr")
def news_aggr_start():
    tfid = news_aggr()
    return tfid


@app.get("/read_news_raw")
def read_news_raw(q: Optional[str] = None):
    logger.info(f"ES ë°ì´í„° ì¡°íšŒ ìš”ì²­: query={q}")
    try:
        news_list = get_news_raw(q)
        if news_list is None:
            return {"status": "error", "message": "ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        return news_list
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.get("/test")
async def get_test_page(request: Request):
    if not request.session.get("user_id"):
        return RedirectResponse(url="/login")
    return FileResponse("view/html/test.html")


@app.get("/npti/q")
async def get_questions(request: Request, db: Session = Depends(get_db)):
    if not request.session.get("user_id"):
        return JSONResponse(status_code=401, content={"message": "ë¡œê·¸ì¸ í•„ìš”"})

    query = text("SELECT question_id, question_text, npti_axis, question_ratio FROM npti_question")
    result = db.execute(query).fetchall()
    return [dict(row._mapping) for row in result]


@app.post("/test")
async def save_test_result(request: Request, payload: dict = Body(...), db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    if not user_id:
        return JSONResponse(status_code=401, content={"success": False, "message": "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."})

    try:
        # ê°œë³„ ë‹µë³€ ë°ì´í„° ê°€ê³µ ë° ì €ì¥ (insert_user_answers í˜¸ì¶œ)
        answers_list = [
            {"question_no": int(str(q_id).replace('q', '')), "answer_value": val}
            for q_id, val in payload.get("answers", {}).items()
        ]
        insert_user_answers(db, user_id, answers_list)

        # NPTI ê²°ê³¼ ë°ì´í„° ê°€ê³µ (insert_user_npti í˜¸ì¶œ)
        scores = payload.get("scores", {})
        updated_at = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        npti_params = {
            "user_id": user_id,
            "npti_code": payload.get("npti_result"),
            "long_score": scores.get('long'),
            "short_score": scores.get('short'),
            "content_score": scores.get('content'),
            "tale_score": scores.get('tale'),
            "fact_score": scores.get('fact'),
            "insight_score": scores.get('insight'),
            "positive_score": scores.get('positive'),
            "negative_score": scores.get('negative'),
            "updated_at": updated_at
        }
        insert_user_npti(db, npti_params)

        db.commit()  # ìµœì¢… ì»¤ë°‹
        request.session['hasNPTI']=True
        request.session['npti_result'] = payload.get("npti_result")
        return {"success": True, "message": "ì €ì¥ ì™„ë£Œ"}

    except Exception as e:
        db.rollback()
        return JSONResponse(status_code=500, content={"success": False, "message": str(e)})

@app.get("/result")
async def get_result_page(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    if not user_id:
        return RedirectResponse(url="/login")
    user_data = get_user_npti_info(db, user_id)
    if user_id and not user_data:
        return RedirectResponse(url="/test")
    return FileResponse("view/html/result.html")

@app.post("/result")
def api_get_result_data(request: Request, db: Session = Depends(get_db)):
    try:
        user_id = request.session.get("user_id")
        # user_name = request.session.get("user_name", "ë…ì")

        if not user_id:
            return {"isLoggedIn": False, "hasNPTI": False}

        # 1. ìµœì‹  ë°ì´í„° ì¡°íšŒ (ì¼ë°˜ í•¨ìˆ˜ í˜¸ì¶œ)
        user_data = get_user_npti_info(db, user_id)

        if not user_data:
            return {"isLoggedIn": True, "hasNPTI": False, "user_id": user_id}

        # 2. ë‚ ì§œ ì§ë ¬í™” (JSON ì—ëŸ¬ ë°©ì§€ í•µì‹¬)
        if user_data.get('updated_at') and isinstance(user_data['updated_at'], datetime):
            user_data['updated_at'] = user_data['updated_at'].strftime('%Y-%m-%d %H:%M:%S')

        # 3. í†µí•© ë°ì´í„° ë°˜í™˜ (ì»¬ëŸ¼ëª… ì´ìŠˆ í•´ê²°ì„ ìœ„í•´ ë³„ì¹­ì„ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤)
        return {
            "isLoggedIn": True,
            "hasNPTI": True,
            "user_id": user_id,
            # "user_name": user_name,
            "user_npti": user_data,
            "code_info": get_npti_code_by_code(db, user_data['npti_code']), # ì—¬ê¸°ì„œ ì—ëŸ¬ í•´ê²°ë¨
            "all_types": get_all_npti_type(db) # ì—¬ê¸°ì„œë„ info_type AS information_type ì ìš© í•„ìš”
        }
    except Exception as e:
        print(f"ì„œë²„ ì—ëŸ¬ ìƒì„¸: {str(e)}")
        return JSONResponse(status_code=500, content={"message": str(e)})


@app.get("/search")
def main():
    return FileResponse("view/html/search.html")


es = Elasticsearch(
    "http://localhost:9200",
    basic_auth=("elastic", "elastic"),
    verify_certs=False
)

FIELD_MAP = {
    "title": "title_tokens",
    "content": "content_tokens",
    "media": "media",
    "category": "category"
}

@app.post("/search")
def search_news(payload: dict = Body(...)):
    # 1. ìš”ì²­ ë°ì´í„° ì¶”ì¶œ
    query_obj = payload.get("query", {}).get("multi_match", {})
    q = query_obj.get("query", "")
    fields = query_obj.get("fields", ["title", "content", "media", "category"])

    from_idx = payload.get("from", 0)
    size = payload.get("size", 20)
    sort_option = payload.get("sort", ["_score"])

    # ê²€ìƒ‰ì–´ ê³µë°± ë°©ì–´
    if not q.strip():
        return {"hits": {"total": {"value": 0}, "hits": []}}

    # 2. í•„ë“œ ë§¤í•‘ ë° ê²€ìƒ‰ Body êµ¬ì„± (FIELD_MAPì„ í†µí•´ ì‹¤ì œ í† í° í•„ë“œëª…ìœ¼ë¡œ ë³€í™˜)
    field_list = [FIELD_MAP.get(f, f) for f in fields]

    search_condition = {
        "query": {
            "multi_match": {
                "query": q,
                "fields": field_list,
                "operator": "or"
            }
        },
        "from": from_idx,
        "size": size,
        "sort": sort_option
    }

    try:
        # 3. ES ê²€ìƒ‰ ì‹¤í–‰ (JS ë Œë”ë§ì— í•„ìš”í•œ í•„ë“œë“¤ì„ _sourceì— ëª…ì‹œ)
        res = es.search(
            index="news_raw",
            body=search_condition,
            _source=["title", "content", "media", "category", "img", "pubdate"]
        )
        return res  # Elasticsearch ì‘ë‹µ êµ¬ì¡° ê·¸ëŒ€ë¡œ ë°˜í™˜

    except ESConnectionError as e:
        logger.error(f"ES ì—°ê²° ì‹¤íŒ¨: {e}")
        return {"hits": {"total": {"value": 0}, "hits": []}}
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {"hits": {"total": {"value": 0}, "hits": []}}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    # ----------------------------------------------------------------------------
@app.get("/npti/types", response_model=list[npti_type_response])
def npti_type_list(db: Session = Depends(get_db)):
    try:
        return get_all_npti_type(db)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.get("/npti/types/group", response_model=list[npti_type_response])
def npti_type_by_group(group: str = Query(...), db: Session = Depends(get_db)):
    try:
        return get_npti_type_by_group(db, group)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.get("/npti/codes", response_model=list[npti_code_response])
def npti_code_list(db: Session = Depends(get_db)):
    try:
        return get_all_npti_codes(db)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

@app.get("/npti/codes/{code}", response_model=npti_code_response)
def npti_code_detail(code: str, db: Session = Depends(get_db)):
    try:
        result = get_npti_code_by_code(db, code)
        if not result:
            return {'msg': 'npti_codeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        return result
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ê´€ë¦¬ì
@app.get("/npti/questions", response_model=list[npti_question_response])
def npti_question_list(db: Session = Depends(get_db)):
    try:
        return get_all_npti_questions(db)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ì‚¬ìš©ì
@app.get("/npti/questions/axis", response_model=list[npti_question_response])
def npti_question_by_axis(axis: str = Query(...), db: Session = Depends(get_db)):
    try:
        return get_npti_questions_by_axis(db, axis)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ê°€ì…ìš©
@app.get("/signup")
async def get_signup_page(request: Request):
    # isLoggedIn ëŒ€ì‹  ë³´í†µ ë¡œê·¸ì¸ ì‹œ ì €ì¥í•œ user_id ë“±ìœ¼ë¡œ ì²´í¬í•©ë‹ˆë‹¤.
    user_id = request.session.get("user_id")
    # ì´ë¯¸ ë¡œê·¸ì¸ëœ ì‚¬ìš©ìê°€ ê°€ì… í˜ì´ì§€ì— ì ‘ê·¼í•˜ë©´ ë©”ì¸ìœ¼ë¡œ íŠ•ê²¨ëƒ„
    if user_id:
        return RedirectResponse(url="/")
    # ë¡œê·¸ì¸ ì•ˆ ëœ ì‚¬ìš©ìì—ê²Œë§Œ íšŒì›ê°€ì… íŒŒì¼ ì „ì†¡
    return FileResponse("view/html/signup.html")

# 2. [POST] íšŒì›ê°€ì… ë°ì´í„° ì²˜ë¦¬í•˜ê¸°
@app.post("/signup")
def create_user(req: UserCreateRequest, db: Session = Depends(get_db)):
    # DBì— ì‚¬ìš©ì ì €ì¥
    insert_user(db, req.model_dump())
    db.commit()
    return {"success":True}

@app.get("/users/check-id")
def check_user_id(user_id: str, db: Session = Depends(get_db)):
    sql = """
        SELECT 1
        FROM user_info
        WHERE user_id = :user_id
        LIMIT 1
    """
    exists = db.execute(text(sql), {"user_id": user_id}).first() is not None
    return {"exists": exists}

# ë¡œê·¸ì¸
@app.get("/login")
def page_login(request: Request):
    user_id = request.session.get("user_id")
    if user_id:
        return RedirectResponse(url="/")
    return FileResponse("view/html/login.html")

@app.post("/login")
def login(req: dict, request: Request, db: Session = Depends(get_db)):
    user_id = req.get("user_id")
    user_pw = req.get("user_pw")

    # 1. ì¸ì¦ í™•ì¸
    if not authenticate_user(db, user_id, user_pw):
        return {"success": False, "message": "ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤."}

    # 2. DBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    raw_data = get_user_npti_info(db, user_id)

    # 3. ì„¸ì…˜ ì €ì¥
    request.session["user_id"] = user_id


    if raw_data: # ìœ ì € NPTIê°€ ìˆì„ ê²½ìš°
        # ğŸ’¡ í•µì‹¬: ë³µì¡í•œ ê°ì²´ ì „ì²´ë¥¼ ë„£ì§€ ë§ê³ ,
        # í•„ìš”í•œ 'npti_code'(ë¬¸ìì—´)ë§Œ ë”± ê³¨ë¼ì„œ ë„£ìŠµë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ RowMappingì´ë‚˜ ë‚ ì§œ ì—ëŸ¬ê°€ ì „í˜€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        request.session["npti_result"] = raw_data["npti_code"]
        request.session["hasNPTI"] = True
    else:# ìœ ì € NPTIê°€ ì—†ì„ ê²½ìš°
        request.session["npti_result"] = None
        request.session["hasNPTI"] = False

    return {"success": True}

@app.post("/users/withdraw")
async def withdraw(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    if not user_id:
        return JSONResponse(status_code=401, content={"success": False})

    # 1. DB ìƒíƒœ ë³€ê²½ (ë¹„í™œì„±í™”)
    deactivate_user(db, user_id)

    # 2. ì„¸ì…˜ ì‚­ì œ (ë¡œê·¸ì•„ì›ƒ ì²˜ë¦¬)
    request.session.clear()
    return {"success": True}

#ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸
@app.get("/auth/me")
def auth_me(request: Request):
    session = request.session

    user_id = session.get("user_id")
    npti_result = session.get("npti_result")
    logger.info(npti_result)

    return {
        # ë¡œê·¸ì¸ ì—¬ë¶€
        "isLoggedIn": bool(user_id),

        # ì„¸ì…˜ ìœ íš¨ì„± (ì´ ìš”ì²­ì— ë„ë‹¬í–ˆìœ¼ë©´ True)
        "isSessionValid": True,

        # ë¶€ê°€ ì •ë³´
        "user_id": user_id,
        "hasNPTI": bool(npti_result),
        "nptiResult": npti_result
    }

@app.post("/logout")
def logout(request: Request):
    request.session.clear()
    return {
        "success": True
    }

@app.get("/api/about")
def get_about(db: Session = Depends(get_db)):

    # 1. NPTI ê¸°ì¤€ (npti_type)
    type_rows = db.execute("""
        SELECT npti_group, npti_type, npti_kor
        FROM npti_type
        ORDER BY npti_group, npti_type
    """).fetchall()

    grouped = {}
    for r in type_rows:
        grouped.setdefault(r.npti_group, []).append(r)

    criteria = []
    for group, items in grouped.items():
        if len(items) == 2:
            left, right = items
            criteria.append({
                "title": group.capitalize(),
                "left": f"{left.npti_type} - {left.npti_kor}",
                "right": f"{right.npti_type} - {right.npti_kor}"
            })

    # 2. NPTI ì„±í–¥ (npti_code)
    code_rows = db.execute("""
        SELECT npti_code, type_nick, type_de,
               length_type, article_type, info_type, view_type
        FROM npti_code
        ORDER BY npti_code
    """).fetchall()

    guides = []
    for r in code_rows:
        guides.append({
            "code": r.npti_code,
            "name": r.type_nick,
            "desc": r.type_de,
            "pref": "",  # ë˜ëŠ” ì‹¤ì œ ì„ í˜¸ ì„¤ëª… ì»¬ëŸ¼
            "types": [
                r.length_type,
                r.article_type,
                r.info_type,
                r.view_type
            ]
        })

    return {
        "intro": {
            "title": "NPTIë€?",
            "content": "NPTIëŠ” ë‰´ìŠ¤ ì†Œë¹„ ì„±í–¥ì„ ë¶„ì„í•´ ê°œì¸ì—ê²Œ ë§ëŠ” ë‰´ìŠ¤ ê²½í—˜ì„ ì œê³µí•˜ëŠ” ì§€í‘œì…ë‹ˆë‹¤."
        },
        "criteria": criteria,
        "guides": guides
    }

@app.post("/mypage")
async def get_my_profile(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    if not user_id:
        return JSONResponse(status_code=401, content={"message": "ë¡œê·¸ì¸ í•„ìš”"})

    # ë„êµ¬ ì‚¬ìš©
    user = get_my_page_data(db, user_id)

    if not user:
        return JSONResponse(status_code=404, content={"message": "ì‚¬ìš©ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

    # [ì¤‘ìš”] db_user_info.pyì—ì„œ ì •ì˜í•œ 'userId' í‚¤ê°’ì„ ì‚¬ìš©í•´ì•¼ í•¨
    return {
        "userId": user['userId'],
        "name": user['name'],
        "email": user['email'],
        "birth": user['birth'],
        "age": user['age'],
        "gender": user['gender']
    }


@app.get("/mypage")
async def get_mypage(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")

    # 1. ë¡œê·¸ì¸ ì²´í¬ ë¨¼ì € (DB ì¡°íšŒ ë‚­ë¹„ ë°©ì§€)
    if not user_id:
        return RedirectResponse(url="/login")

    # 2. DB ì¡°íšŒ (scalar ì‚¬ìš© ì¶”ì²œ)
    param = {"user_id": user_id}
    sql = text("select admin from user_info where user_id = :user_id")
    # scalar()ë¥¼ ì“°ë©´ result[0] í•  í•„ìš” ì—†ì´ ë°”ë¡œ ê°’ì´ ë‚˜ì˜´ (ì—†ìœ¼ë©´ None)
    admin_value = db.execute(sql, param).scalar()

    # 3. ê¶Œí•œ ì²´í¬
    if admin_value == 0:  # ê´€ë¦¬ìë©´ ëŒ€ì‹œë³´ë“œë¡œ
        return RedirectResponse(url="/dashboard")

    # 4. ì¼ë°˜ íšŒì›ì´ë©´ ë§ˆì´í˜ì´ì§€ í‘œì‹œ
    return FileResponse("view/html/mypage.html")

@app.get("/curation")
def curation_page(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    if not user_id:
        return RedirectResponse(url="/login")
    user_npti = get_user_npti_info(db, user_id)
    if user_id and not user_npti:
        return RedirectResponse(url="/test")
    return FileResponse("view/html/curation.html")

@app.get("/user/npti/me")
async def get_user_npti(request: Request,db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")

    if not user_id:
        raise HTTPException(status_code=401, detail="Not authenticated")

    # user_nptiì™€ npti_code í…Œì´ë¸” ì¡°ì¸ (ê¸°ë³¸ ì •ë³´ ë° ë³„ì¹­ ì¡°íšŒ)
    result = db.query(
        UserNPTITable,
        NptiCodeTable.type_nick
    ).join(
        NptiCodeTable, UserNPTITable.npti_code == NptiCodeTable.npti_code
    ).filter(
        UserNPTITable.user_id == user_id
    ).order_by(
        UserNPTITable.updated_at.desc()
    ).first()

    # ìœ ì €ëŠ” ìˆìœ¼ë‚˜ NPTI ì—†ìŒ â†’ 404
    if not result:
        raise HTTPException(status_code=404, detail="NPTI data not found")

    user_data, type_nick = result
    npti_code_str = user_data.npti_code

    # ê° ì•ŒíŒŒë²³ì— ë§¤ì¹­ë˜ëŠ” npti_kor ê°’ ê°€ì ¸ì˜¤ê¸° (npti_type í…Œì´ë¸” ì¡°íšŒ)
    # npti_type í…Œì´ë¸”ì—ì„œ NPTI_type ì»¬ëŸ¼ì´ ì½”ë“œì— í¬í•¨ëœ ê²ƒë“¤ë§Œ ì¡°íšŒ
    chars = list(npti_code_str)
    type_items = db.query(NptiTypeTable) \
        .filter(NptiTypeTable.NPTI_type.in_(chars)) \
        .all()

    # ìˆœì„œ(S-T-F-N)ì— ë§ê²Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë§µí•‘ ìƒì„±
    kor_map = {item.NPTI_type: item.npti_kor for item in type_items}
    # ìµœì¢… ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì˜ˆ: ["ì§§ì€", "ì´ì•¼ê¸°í˜•", "ê°ê´€ì ", "ë¹„íŒì "])
    npti_kor_list = [kor_map.get(c, "") for c in chars]

    return {
        "npti_code": npti_code_str,
        "type_nick": type_nick,
        "npti_kor_list": npti_kor_list,
        "updated_at": user_data.updated_at
    }


@app.get("/curated/news")
async def get_curated_news(
        npti: str = Query(...),
        category: str = "all",
        sort_type: str = "accuracy",
        page: int = 1,
        db: Session = Depends(get_db)
):

    ITEMS_PER_PAGE = 20  # í•œ í˜ì´ì§€ì— ê¸°ì‚¬ 20ê°œ
    offset = (page - 1) * ITEMS_PER_PAGE

    # DBì—ì„œ í•´ë‹¹ NPTI_codeë¥¼ ê°€ì§„ news_id ë¦¬ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ê°€ì ¸ì˜´
    news_ids = db.query(ArticlesNPTI.news_id).filter(
        ArticlesNPTI.NPTI_code == npti
    ).all()

    id_list = [id[0] for id in news_ids]
    if not id_list:
        return {"articles": [], "total": 0}

    # ES ì¿¼ë¦¬ ì‘ì„±
    body = {
        "track_total_hits": True,
        "from": offset,
        "size": ITEMS_PER_PAGE,
        "query": {
            "bool": {
                "must": [{"terms": {"news_id": id_list}}]
            }
        }
    }

    if category != "all":
        body["query"]["bool"]["filter"] = [
            {"match": {"category": category}}  #term ì“°ë ¤ë©´ ES ë§¤í•‘ ìˆ˜ì •í•´ì•¼í•¨
        ]

    # 3. ì •ë ¬ ì¡°ê±´ ì²˜ë¦¬
    if sort_type == "latest":
        body["sort"] = [{"pubdate": {"order": "desc"}}]
    else:
        body["sort"] = [{"_score": {"order": "desc"}}]

    try:
        res = es.search(index=ES_INDEX, body=body)
        hits = res["hits"]["hits"]

        # 3. ê¸°ì¡´ search_articleì˜ ë°ì´í„° ê°€ê³µ ë°©ì‹ì„ ê·¸ëŒ€ë¡œ í™œìš©
        articles = []
        for hit in hits:
            src = hit["_source"]
            articles.append({
                "id": src.get("news_id", ""),
                "title": src.get("title", ""),
                "summary": src.get("content", "")[:150] + "...",
                "publisher": src.get("media", ""),
                "date": src.get("pubdate", ""),
                "thumbnail": src.get("img", ""),
                "category": src.get("category", "")
            })

        total_count = res["hits"]["total"]["value"]
        return {
            "articles": articles,
            "total": total_count,
            "sort":body["sort"][0]
        }
    except Exception as e:
        logger.error(f"íë ˆì´ì…˜ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {"articles": [], "total": 0}

@app.get("/update_user_npti")
def update_user_npti(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")
    latest_user_npti = get_user_npti_info(db, user_id)
    long_score = latest_user_npti.get("long_score")
    short_score = latest_user_npti.get("short_score")
    content_score = latest_user_npti.get("content_score")
    tale_score = latest_user_npti.get("tale_score")
    fact_score = latest_user_npti.get("fact_score")
    insight_score = latest_user_npti.get("insight_score")
    positive_score = latest_user_npti.get("positive_score")
    negative_score = latest_user_npti.get("negative_score")
    latest_update_time = latest_user_npti.get('timestamp')
    behavior_log_per_news = search_user_behavior(user_id, latest_update_time) # [[{},{}],[{},{},{},],[{}]] í˜•íƒœ
    for behavior_log in behavior_log_per_news: # [{},{}]
        if not behavior_log:
            continue
        result = model_predict_proba(behavior_log)# {userid:, news_id:, dwell time:, final_read_time:, reading_efficiency: } ê°™ì€ dictionary
        reading_efficiency = result.get('reading_efficiency')
        id = result.get('news_id')
        body = {"query": {"term": {"news_id": id}},"_source": ["content"]}
        response = search_news_condition(body)
        n_word = 0
        if response and response['hits']['hits']:
            source_data = response['hits']['hits'][0]['_source']
            content = source_data.get('content',"")
            if content :
                n_word = len(content.split())
                print(f"news_id : {id} | n_word : {n_word}")
        interest_score = min(1, reading_efficiency * (math.log(n_word+1) / math.log(501)))*10
        result = db.query(ArticlesNPTI).filter(ArticlesNPTI.news_id == id).first()
        news_length_type = result.length_type
        news_article_type = result.article_type
        news_info_type = result.info_type
        news_view_type = result.view_type
        # user_npti ì ìˆ˜ì— interest_score ë°˜ì˜í•˜ëŠ” ë¡œì§ !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! (ê¹Œë¨¹ìœ¼ë©´ ì•ˆë¨)
        if news_length_type == "L":
            long_score += interest_score
            short_score -= interest_score
        else:
            short_score += interest_score
            long_score -= interest_score
        if news_article_type == "C":
            content_score += interest_score
            tale_score -= interest_score
        else:
            tale_score += interest_score
            content_score -= interest_score
        if news_info_type == "F":
            fact_score += interest_score
            insight_score -= interest_score
        else:
            insight_score += interest_score
            fact_score -= interest_score
        if news_view_type == "P":
            positive_score += interest_score
            negative_score -= interest_score
        else:
            negative_score += interest_score
            positive_score -= interest_score
    final_long_score = finalize_score(long_score)
    final_short_score = 100 - final_long_score
    final_tale_score = finalize_score(tale_score)
    final_content_score = 100 - final_tale_score
    final_insight_score = finalize_score(insight_score)
    final_fact_score = 100 - final_insight_score
    final_negative_score = finalize_score(negative_score)
    final_positive_score = 100 - final_negative_score
    final_length_type = "L" if final_long_score > final_short_score else "S"
    final_article_type = "T" if final_tale_score > final_content_score else "C"
    final_info_type = "I" if final_insight_score > final_fact_score else "F"
    final_view_type = "N" if final_negative_score > final_positive_score else "P"
    final_user_npti = final_length_type+final_article_type+final_info_type+final_view_type
    updated_at = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
    query = text("SELECT type_nick, type_de FROM npti_code WHERE npti_code = :code")
    description = db.execute(query, {"code": final_user_npti}).fetchone()
    params = {
        "latest_update_time":latest_update_time,
        "user_id": user_id,
        "npti_code": final_user_npti,
        "type_nick" : description[0],
        "type_de" : description[1],
        "long_score": final_long_score,
        "short_score": final_short_score,
        "content_score": final_content_score,
        "tale_score": final_tale_score,
        "fact_score": final_fact_score,
        "insight_score": final_insight_score,
        "positive_score": final_positive_score,
        "negative_score": final_negative_score,
        "updated_at": updated_at
    }
    insert_user_npti(db, params)
    # long, content, insight, positive
    request.session['user_npti'] = final_user_npti
    request.session['nptiResult'] = final_user_npti
    request.session['npti_result'] = final_user_npti
    print("íšŒì› npti ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤!!!")

    return params

async def update_state_loop():
    while True:
        if not result_queue.empty():
            latest_breaking = result_queue.get()
            if isinstance(latest_breaking, dict) and "final_group" in latest_breaking:
                app.state.breaking_news = latest_breaking
                print("New breaking news data updated!")
        await asyncio.sleep(1)

@app.on_event("startup")
async def startup_event():
    if not sch.running:
        sch.start()
    app.state.breaking_news = {'msg':'ìŠ¤ì¼€ì¥´ëŸ¬ ê°€ë™ ì¤‘ - ë°ì´í„° ì¤€ë¹„ ì¤‘'} # ì´ˆê¸°ê°’
    asyncio.create_task(update_state_loop())

@app.get("/render_breaking")
def render_breaking():
    grouping_result = getattr(app.state, "breaking_news", {"msg": "ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤."})
    breaking_topic = grouping_result.get('final_group') # None or ['news_id1', 'news_id2']
    if not breaking_topic:
        return {"breaking_news": None, "msg":"ë°ì´í„° ì—†ìŒ"}
    id_title_list = []
    for topic in breaking_topic:
        query = {"size": 1,"_source": ["news_id", "title", "timestamp"],
          "query": {"terms": {"news_id": topic}},
          "sort": [{"timestamp": {"order": "desc"}}]}
        res = search_news_condition(query)
        if res and res.get("hits") and res["hits"]["hits"]:
            first_hit = res["hits"]["hits"][0]["_source"]
            id_title = {"id":first_hit["news_id"], "title":first_hit["title"]}
            id_title_list.append(id_title)

    return {"breaking_news": id_title_list, "msg":"ë°ì´í„° ìˆìŒ"}

@app.get("/render_general")
def render_general(category:str):
    news_list = []
    if category == "ì „ì²´" or category == 'all':
        cate_list = ["ì •ì¹˜", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œ/ë¬¸í™”", "IT/ê³¼í•™", "ì„¸ê³„", "ìŠ¤í¬ì¸ ","ì—°ì˜ˆ","ì§€ì—­"]
        for category in cate_list:
            query = {"query": {"match":{"category":category}}, "sort": [{"pubdate": {"order": "desc"}}],
                     "size": 1, "_source": ["news_id", "title", "content", "img"]}
            res = search_news_condition(query)
            src = res["hits"]["hits"][0]["_source"]
            news_item = {"news_id": src.get("news_id", ""),
                         "title": src.get("title", ""),
                         "desc": src.get("content", ""),
                         "img": src.get("img", ""),
                         "link": f"/article?news_id={src['news_id']}"}
            news_list.append(news_item)
    else :
        query = {"query": {"match":{"category":category}}, "sort": [{"pubdate": {"order": "desc"}}],
                 "size": 9, "_source": ["news_id", "title", "content", "img"]}
        res = search_news_condition(query)
        for hit in res["hits"]["hits"]:
            src = hit["_source"]
            news_item = {"news_id": src.get("news_id", ""),
                         "title": src.get("title", ""),
                         "desc": src.get("content", ""),
                         "img": src.get("img", ""),
                         "link": f"/article?news_id={src['news_id']}"}
            news_list.append(news_item)
    return news_list

@app.get("/render_general_npti")
def render_general(category:str, npti_code:str, db: Session = Depends(get_db)):
    news_list = []
    sql = text("select news_id from articles_npti where npti_code = :code")
    params = {"code":npti_code}
    news_ids = db.execute(sql, params).scalars().fetchall()
    if not news_ids:
        return []
    if category == "ì „ì²´" or category == 'all':
        cate_list = ["ì •ì¹˜", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œ/ë¬¸í™”", "IT/ê³¼í•™", "ì„¸ê³„", "ìŠ¤í¬ì¸ ", "ì—°ì˜ˆ", "ì§€ì—­"]
        for category in cate_list:
            query = {"size": 1,"_source": ["news_id", "title", "content", "img"],"sort": [{"pubdate": {"order": "desc"}}],
                    "query": {"bool": {"must": {"match":{"category":category}},"filter": [{"terms": {"news_id": news_ids}}]}}}
            res = search_news_condition(query)
            if res["hits"]["hits"]:
                src = res["hits"]["hits"][0]["_source"]
                news_item = {"news_id": src.get("news_id", ""),
                             "title": src.get("title", ""),
                             "desc": src.get("content", ""),
                             "img": src.get("img", ""),
                             "link": f"/article?news_id={src['news_id']}"}
                news_list.append(news_item)
    else :
        query = {"size": 9,"_source": ["news_id", "title", "content", "img"],"sort": [{"pubdate": {"order": "desc"}}],
            "query": {"bool": {"must": {"match":{"category":category}},"filter": [{"terms": {"news_id": news_ids}}]}}}
        res = search_news_condition(query)
        for hit in res["hits"]["hits"]:
            src = hit["_source"]
            news_item = {"news_id": src.get("news_id", ""),
                         "title": src.get("title", ""),
                         "desc": src.get("content", ""),
                         "img": src.get("img", ""),
                         "link": f"/article?news_id={src['news_id']}"}
            news_list.append(news_item)
    return news_list

@app.get("/profile-edit")
async def get_profile_edit_page(request: Request):
    user_id = request.session.get("user_id")
    if not user_id:
        # ë¡œê·¸ì¸ ì•ˆ ëìœ¼ë©´ HTMLì¡°ì°¨ ë³´ì—¬ì£¼ì§€ ì•Šê³  ì¦‰ì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return RedirectResponse(url="/")
    return FileResponse("view/html/profile-edit.html")

@app.get("/users/profile")
async def get_user_profile(user_id: str = Query(...), db: Session = Depends(get_db)):
    """ê°€ê³µëœ í”„ë¡œí•„ ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ëŠ” API"""
    user_data = get_my_page_data(db, user_id)
    if not user_data:
        raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return user_data


@app.post("/users/verify-password")
async def verify_password_check(data:dict, db:Session = Depends(get_db)):
    user_id = data.get("user_id")
    current_pw = data.get("current_password")

    user = db.query(UserInfo).filter(UserInfo.user_id == user_id).first()
    if user and user.user_pw and verify_password(current_pw, user.user_pw):
        return {"success": True, "message": "í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤."}

    return {"success": False, "message": "í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

@app.post("/users/check-new-password")
def check_new_password_api(data: dict, db: Session = Depends(get_db)):
    user_id = data.get("user_id")
    new_password = data.get("new_password")

    user = db.query(UserInfo).filter(UserInfo.user_id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    is_same = verify_password(new_password, user.user_pw)
    return {"is_same": is_same}

@app.post("/users/update")
async def update_user(data: UserUpdate, db: Session = Depends(get_db)):
    try:
        user = db.query(UserInfo).filter(UserInfo.user_id == data.user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ (sha256 í•´ì‹œ ë¹„êµ)
        if not verify_password(data.current_password, user.user_pw):
            raise HTTPException(status_code=400, detail="í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # ë°ì´í„° ì—…ë°ì´íŠ¸
        user.user_name = data.user_name
        user.user_age = data.user_age
        user.user_email = data.user_email
        if data.user_gender:
            user.user_gender = 1 if "female" in data.user_gender else 0

        try:
            if data.user_birth:
                # ë¬¸ìì—´ "YYYY-MM-DD"ë¥¼ íŒŒì´ì¬ date ê°ì²´ë¡œ ë³€í™˜
                user.user_birth = datetime.strptime(data.user_birth, "%Y-%m-%d").date()
        except ValueError:
            raise HTTPException(status_code=400, detail="ìƒë…„ì›”ì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (YYYY-MM-DD)")

        if data.new_password and data.new_password.strip():
            user.user_pw = hash_password(data.new_password)

        db.commit()
        return {"success": True}

    except Exception as e:
        db.rollback()
        logger.info(f'ìœ ì € í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì¤‘ ì„œë²„ ì—ëŸ¬ ë°œìƒ: {str(e)}')
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}")


@app.get("/dashboard")
def dashboard(request: Request, db: Session = Depends(get_db)):
    user_id = request.session.get("user_id")

    # 1. ë¡œê·¸ì¸ ì²´í¬ ë¨¼ì €
    if not user_id:
        return RedirectResponse(url="/login")

    # 2. DB ì¡°íšŒ
    param = {"user_id": user_id}
    sql = text("select admin from user_info where user_id = :user_id")
    admin_value = db.execute(sql, param).scalar()

    # 3. ê¶Œí•œ ì²´í¬
    if admin_value == 0: # ê´€ë¦¬ìë§Œ í†µê³¼
        return FileResponse("view/html/dashboard.html")
    else: # ì¼ë°˜ íšŒì›ì€ ë©”ì¸ìœ¼ë¡œ ì¶”ë°©
        return RedirectResponse(url="/")


@app.get("/members_statistics")
def members_statistics(db: Session = Depends(get_db)):
    today_str = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d')
    today = datetime.now(timezone(timedelta(hours=9)))
    this_monday = today - timedelta(days=today.weekday())
    this_monday_str = this_monday.strftime('%Y-%m-%d')
    this_month_start = today.replace(day=1)
    this_month_str = this_month_start.strftime('%Y-%m-%d')

    print(f'ë°ì´í„° ì¶”ì¶œ ì‹œì‘')

    # [Helper í•¨ìˆ˜] DB ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    def rows_to_dict(result_proxy):
        return [dict(row._asdict()) for row in result_proxy]

    # [Helper í•¨ìˆ˜] ë‹¨ì¼ í–‰(1 row) ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    def row_to_dict(row):
        return dict(row._asdict()) if row else {}

    try:
        # =========================================================
        # 1. NPTI íšŒì› ë¶„í¬ (Pie Chartìš©)
        # =========================================================

        # 1-1) NPTI ì½”ë“œë³„ ë¹„ìœ¨ -------------------------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql1_1 = text("""
            WITH LatestUserNPTI AS (
                SELECT 
                    user_id,  
                    npti_code,
                    ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY updated_at DESC) as rn
                FROM user_npti
            )
            SELECT 
                IFNULL(L.npti_code, 'ë¯¸ì§„ë‹¨') AS npti_code, 
                COUNT(*) as count 
            FROM user_info U
            LEFT JOIN LatestUserNPTI L 
                ON U.user_id = L.user_id AND L.rn = 1 
            WHERE U.activation = 1 AND U.admin = 1
            GROUP BY IFNULL(L.npti_code, 'ë¯¸ì§„ë‹¨')
            ORDER BY count DESC;
        """)
        result1_1 = rows_to_dict(db.execute(sql1_1).fetchall())
        print('result1_1 ì™„ë£Œ')


        # 1-2) ì—°ë ¹ëŒ€ë³„ ë¹„ìœ¨ ----------------------------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql1_2 = text("""
            SELECT 
                CASE 
                    WHEN user_age < 20 THEN '10ëŒ€ ì´í•˜' 
                    WHEN user_age >= 20 AND user_age < 30 THEN '20ëŒ€'
                    WHEN user_age >= 30 AND user_age < 40 THEN '30ëŒ€' 
                    WHEN user_age >= 40 AND user_age < 50 THEN '40ëŒ€'
                    WHEN user_age >= 50 AND user_age < 60 THEN '50ëŒ€' 
                    ELSE '60ëŒ€ ì´ìƒ' 
                END AS age_group, 
                COUNT(*) AS count
            FROM user_info 
            WHERE activation = 1 and admin = 1
            GROUP BY age_group 
            ORDER BY age_group;
        """)
        # DB ì‹¤í–‰ ê²°ê³¼
        result1_2_1 = rows_to_dict(db.execute(sql1_2).fetchall())
        # [í›„ì²˜ë¦¬] ëª¨ë“  ì—°ë ¹ëŒ€ ì¹´í…Œê³ ë¦¬ ì •ì˜
        all_groups = ['10ëŒ€ ì´í•˜', '20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€ ì´ìƒ']
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ë§¤í•‘ (ì˜ˆ: {'20ëŒ€': 50, '10ëŒ€ ì´í•˜': 15 ...})
        result_map = {row['age_group']: row['count'] for row in result1_2_1}
        # ë¹ˆ ì¹´í…Œê³ ë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì„œ ìµœì¢… ë¦¬ìŠ¤íŠ¸ ìƒì„±
        result1_2 = [
            {'age_group': group, 'count': result_map.get(group, 0)}
            for group in all_groups
        ]
        print(result1_2) # ê²°ê³¼: ëª¨ë“  ì—°ë ¹ëŒ€ê°€ ìˆœì„œëŒ€ë¡œ ì¡´ì¬í•˜ë©°, ì—†ëŠ” ê·¸ë£¹ì€ count: 0ìœ¼ë¡œ ë³´ì¥ë¨

        # 1-3) ì„±ë³„ ë¹„ìœ¨ --------------------------------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql1_3 = text("""SELECT user_gender, COUNT(*) as count FROM user_info 
            WHERE activation = 1 and admin = 1 GROUP BY user_gender;""")

        # 1. DB ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ë°ì´í„°ê°€ ìˆëŠ” ì„±ë³„ë§Œ ë‚˜ì˜´)
        result1_3_raw = rows_to_dict(db.execute(sql1_3).fetchall())

        # 2. [í›„ì²˜ë¦¬] 0ê°’ ì±„ìš°ê¸°
        # ë³´ì¥í•´ì•¼ í•  í‚¤ê°’ ëª©ë¡ (0ê³¼ 1)
        target_genders = [0, 1]

        # ê²€ìƒ‰ ì†ë„ë¥¼ ìœ„í•´ DB ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ( {0: 15, 1: 20} í˜•íƒœ )
        gender_map = {row['user_gender']: row['count'] for row in result1_3_raw}

        # íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸(0, 1)ë¥¼ ìˆœíšŒí•˜ë©° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ count: 0ìœ¼ë¡œ ì„¤ì •
        result1_3 = [
            {'user_gender': g, 'count': gender_map.get(g, 0)}
            for g in target_genders
        ]

        print('result1_3 (ì„±ë³„ 0, 1 í¬í•¨) ì™„ë£Œ')

        # =========================================================
        # 2. NPTI ì½”ë“œë³„ ë³€í™” ì¶”ì´ (Line Graphìš©)
        # =========================================================

        # 2-1) ì¼ë³„ ëˆ„ì  (ìµœê·¼ 7ì¼ ë‚ ì§œë³„ ëª¨ë“  ìœ ì €ì˜ ìµœì¢… ìƒíƒœ) --------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql2_1 = text(f"""
            WITH RECURSIVE Past7Days AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 7ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{today_str}' - INTERVAL 6 DAY AS date_period
                UNION ALL
                SELECT date_period + INTERVAL 1 DAY
                FROM Past7Days
                WHERE date_period < '{today_str}'
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] ì¡´ì¬í•˜ëŠ” ëª¨ë“  NPTI ì½”ë“œ ê°€ì ¸ì˜¤ê¸° (16ê°œ ìœ í˜• ë“±)
                -- (npti_code í…Œì´ë¸”ì´ ìˆë‹¤ê³  ê°€ì •, ë§Œì•½ ì—†ë‹¤ë©´ DISTINCT npti_code FROM user_npti ì‚¬ìš©)
                SELECT npti_code FROM npti_code
            ),
            DateCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (7ì¼ ë‚ ì§œ) x (ëª¨ë“  NPTI ì½”ë“œ) ì¡°í•© ìƒì„±
                -- ë°ì´í„°ê°€ ì—†ì–´ë„ ì´ ì¡°í•©ì€ ë¬´ì¡°ê±´ ì¡´ì¬í•´ì•¼ í•¨
                SELECT d.date_period, c.npti_code
                FROM Past7Days d
                CROSS JOIN AllNPTICodes c
            ),
            DailySnapshot AS (
                -- 4. [ì‹¤ì œ ë°ì´í„°] ìœ ì €ë³„ ì¼ìë³„ ìµœì¢… ìƒíƒœ ê³„ì‚°
                SELECT 
                    d.date_period,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY d.date_period, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past7Days d
                LEFT JOIN user_npti u
                    ON u.updated_at < d.date_period + INTERVAL 1 DAY
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                G.date_period, 
                G.npti_code, 
                -- 5. ê·¸ë¦¬ë“œ(G)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°(S)ë¥¼ ë¶™ì—¬ì„œ ì¹´ìš´íŠ¸
                COUNT(CASE WHEN S.rn = 1 THEN 1 END) as user_count
            FROM DateCodeGrid G
            LEFT JOIN DailySnapshot S
              ON G.date_period = S.date_period 
              AND G.npti_code = S.npti_code
            GROUP BY G.date_period, G.npti_code
            ORDER BY G.date_period ASC, G.npti_code ASC;
        """)

        result2_1 = rows_to_dict(db.execute(sql2_1).fetchall())
        print('result2_1 (ìµœê·¼ 7ì¼ ëˆ„ì  - 0í¬í•¨) ì™„ë£Œ')

        # 2-2) ì£¼ë³„ ëˆ„ì  (í•´ë‹¹ ì£¼ì°¨ ê¸°ì¤€, ëª¨ë“  ìœ ì €ì˜ ìµœì¢… ìƒíƒœ) --------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql2_2 = text(f"""
            WITH RECURSIVE Past4Weeks AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 4ì£¼ ì›”ìš”ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{this_monday_str}' AS week_start
                UNION ALL
                SELECT week_start - INTERVAL 1 WEEK
                FROM Past4Weeks
                WHERE week_start > '{this_monday_str}' - INTERVAL 3 WEEK
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] ëª¨ë“  NPTI ì½”ë“œ ê°€ì ¸ì˜¤ê¸° (16ê°œ ìœ í˜•)
                SELECT npti_code FROM npti_code
            ),
            WeekCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (4ì£¼) x (ëª¨ë“  NPTI ì½”ë“œ) ì¡°í•©
                -- ë°ì´í„° ìœ ë¬´ì™€ ìƒê´€ì—†ì´ ë¬´ì¡°ê±´ ì¡´ì¬í•˜ëŠ” ë¼ˆëŒ€
                SELECT w.week_start, c.npti_code
                FROM Past4Weeks w
                CROSS JOIN AllNPTICodes c
            ),
            WeeklySnapshot AS (
                -- 4. [ì‹¤ì œ ë°ì´í„°] ì£¼ì°¨ë³„ ìœ ì €ì˜ ìµœì¢… ìƒíƒœ ìŠ¤ëƒ…ìƒ·
                SELECT 
                    w.week_start,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY w.week_start, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past4Weeks w
                LEFT JOIN user_npti u
                    -- í•´ë‹¹ ì£¼ì°¨ ì¼ìš”ì¼ ë°¤(ë‹¤ìŒì£¼ ì›”ìš”ì¼ 0ì‹œ)ê¹Œì§€ì˜ ëˆ„ì  ê¸°ë¡
                    ON u.updated_at < w.week_start + INTERVAL 1 WEEK
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM-DD ~ YYYY-MM-DD' í˜•íƒœë¡œ ë³€í™˜
                CONCAT(G.week_start, '\n~ ', DATE_ADD(G.week_start, INTERVAL 6 DAY)) AS date_period,

                G.npti_code, 

                -- 5. ê·¸ë¦¬ë“œ(G)ì— ë°ì´í„°(S)ë¥¼ ë§¤í•‘í•˜ì—¬ ì¹´ìš´íŠ¸ (ì—†ìœ¼ë©´ 0)
                COUNT(CASE WHEN S.rn = 1 THEN 1 END) as user_count
            FROM WeekCodeGrid G
            LEFT JOIN WeeklySnapshot S
              ON G.week_start = S.week_start 
              AND G.npti_code = S.npti_code
            GROUP BY G.week_start, G.npti_code
            ORDER BY G.week_start ASC, G.npti_code ASC;
        """)

        result2_2 = rows_to_dict(db.execute(sql2_2).fetchall())
        print('result2_2 (ì£¼ê°„ ê¸°ê°„ í‘œì‹œ - 0í¬í•¨) ì™„ë£Œ')

        # 2-3) ì›”ë³„ ëˆ„ì  (í•´ë‹¹ ì›” ê¸°ì¤€, ëª¨ë“  ìœ ì €ì˜ ìµœì¢… ìƒíƒœ) ------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        sql2_3 = text(f"""
            WITH RECURSIVE Past6Months AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 6ê°œì›” 'ë§¤ì›” 1ì¼' ìƒì„±
                SELECT '{this_month_str}' AS month_start
                UNION ALL
                SELECT month_start - INTERVAL 1 MONTH
                FROM Past6Months
                WHERE month_start > '{this_month_str}' - INTERVAL 5 MONTH
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] ëª¨ë“  NPTI ì½”ë“œ ê°€ì ¸ì˜¤ê¸° (16ê°œ ìœ í˜•)
                SELECT npti_code FROM npti_code
            ),
            MonthCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (6ê°œì›”) x (ëª¨ë“  NPTI ì½”ë“œ) ì¡°í•©
                -- ë°ì´í„°ê°€ ì—†ì–´ë„ ë¬´ì¡°ê±´ ì¡´ì¬í•´ì•¼ í•˜ëŠ” ë¼ˆëŒ€
                SELECT m.month_start, c.npti_code
                FROM Past6Months m
                CROSS JOIN AllNPTICodes c
            ),
            MonthlySnapshot AS (
                -- 4. [ì‹¤ì œ ë°ì´í„°] ì›”ë³„ ìœ ì €ì˜ ìµœì¢… ìƒíƒœ ìŠ¤ëƒ…ìƒ·
                SELECT 
                    m.month_start,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY m.month_start, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past6Months m
                LEFT JOIN user_npti u
                    -- í•´ë‹¹ ì›”ì˜ ë§ì¼(ë‹¤ìŒë‹¬ 1ì¼ 0ì‹œ ì „)ê¹Œì§€ì˜ ëˆ„ì  ê¸°ë¡
                    ON u.updated_at < m.month_start + INTERVAL 1 MONTH
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM' í˜•íƒœë¡œ ë³€í™˜
                DATE_FORMAT(G.month_start, '%Y-%m') AS date_period,

                G.npti_code, 

                -- 5. ê·¸ë¦¬ë“œ(G)ì— ë°ì´í„°(S)ë¥¼ ë§¤í•‘í•˜ì—¬ ì¹´ìš´íŠ¸ (ì—†ìœ¼ë©´ 0)
                COUNT(CASE WHEN S.rn = 1 THEN 1 END) as user_count
            FROM MonthCodeGrid G
            LEFT JOIN MonthlySnapshot S
              ON G.month_start = S.month_start 
              AND G.npti_code = S.npti_code
            GROUP BY G.month_start, G.npti_code
            ORDER BY G.month_start ASC, G.npti_code ASC;
        """)

        result2_3 = rows_to_dict(db.execute(sql2_3).fetchall())
        print('result2_3 (ìµœê·¼ 6ê°œì›” ëˆ„ì  - 0í¬í•¨) ì™„ë£Œ')

        # =========================================================
        # 3. NPTI 8ê°œ ì†ì„±ë³„ ë¶„í¬ (Bar Chartìš©) ---------------------------------- ì¿¼ë¦¬ ê²€ì¦ ì™„ë£Œ
        # =========================================================
        sql3 = text("""
            WITH LatestUserSnapshot AS (
                SELECT 
                    u.user_id,
                    u.npti_code,
                    -- ìœ ì €ë³„ ê°€ì¥ ìµœì‹  ê¸°ë¡ ìˆœìœ„ ë§¤ê¸°ê¸°
                    ROW_NUMBER() OVER (PARTITION BY u.user_id ORDER BY u.updated_at DESC) as rn
                FROM user_npti u
            )
            SELECT 
                COUNT(CASE WHEN C.length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN C.length_type = 'S' THEN 1 END) AS S_count,

                COUNT(CASE WHEN C.article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN C.article_type = 'T' THEN 1 END) AS T_count,

                COUNT(CASE WHEN C.info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN C.info_type = 'F' THEN 1 END) AS F_count,

                COUNT(CASE WHEN C.view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN C.view_type = 'N' THEN 1 END) AS N_count
            FROM LatestUserSnapshot S
            -- [í•µì‹¬ ìˆ˜ì •] user_info í…Œì´ë¸”ê³¼ ì¡°ì¸í•˜ì—¬ íšŒì› ìƒíƒœ í™•ì¸
            JOIN user_info UI ON S.user_id = UI.user_id
            -- NPTI ì†ì„±(L/S, C/T...) ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì¡°ì¸
            JOIN npti_code C ON S.npti_code = C.npti_code
            WHERE S.rn = 1                 -- ìµœì‹  ê¸°ë¡ë§Œ
              AND UI.activation = 1        -- í™œì„±í™”ëœ íšŒì›ë§Œ
              AND UI.admin = 1;            -- ì¼ë°˜ íšŒì›ë§Œ
        """)
        result3 = row_to_dict(db.execute(sql3).fetchone())
        print('result3 ì™„ë£Œ')

        # =========================================================
        # 4. NPTI 8ê°œ ì†ì„±ë³„ ë³€í™” ì¶”ì´ (Line Graphìš©)
        # =========================================================

        # 4-1) ì¼ë³„ (ëˆ„ì  ê¸°ì¤€)
        sql4_1 = text(f"""
            WITH RECURSIVE Past7Days AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 7ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{today_str}' - INTERVAL 6 DAY AS date_period
                UNION ALL
                SELECT date_period + INTERVAL 1 DAY
                FROM Past7Days
                WHERE date_period < '{today_str}'
            ),
            DailySnapshot AS (
                -- 2. [ìŠ¤ëƒ…ìƒ·] ë‚ ì§œë³„ ìœ ì €ë“¤ì˜ ìµœì¢… ìƒíƒœ
                SELECT 
                    d.date_period,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY d.date_period, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past7Days d
                LEFT JOIN user_npti u
                    ON u.updated_at < d.date_period + INTERVAL 1 DAY
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                P.date_period,

                -- 4. ìœ íš¨í•œ ë°ì´í„°(rn=1)ê°€ ìˆì„ ë•Œë§Œ ì¹´ìš´íŠ¸, ì—†ìœ¼ë©´ 0
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'S' THEN 1 END) AS S_count,

                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'T' THEN 1 END) AS T_count,

                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'F' THEN 1 END) AS F_count,

                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'N' THEN 1 END) AS N_count

            FROM Past7Days P  -- [í•µì‹¬] ê¸°ì¤€ì´ ë˜ëŠ” íƒ€ì„ë¼ì¸ì„ ë¨¼ì € ë‘¡ë‹ˆë‹¤.
            LEFT JOIN DailySnapshot S
                ON P.date_period = S.date_period 
            LEFT JOIN npti_code C 
                ON S.npti_code = C.npti_code
            GROUP BY P.date_period
            ORDER BY P.date_period ASC;
        """)

        result4_1 = rows_to_dict(db.execute(sql4_1).fetchall())
        print('result4_1 (ìµœê·¼ 7ì¼ ìƒì„¸ ë¶„í¬ - 0í¬í•¨) ì™„ë£Œ')

        # 4-2) ì£¼ë³„ (ëˆ„ì  ê¸°ì¤€)
        sql4_2 = text(f"""
            WITH RECURSIVE Past4Weeks AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 4ì£¼ ì›”ìš”ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{this_monday_str}' AS week_start
                UNION ALL
                SELECT week_start - INTERVAL 1 WEEK
                FROM Past4Weeks
                WHERE week_start > '{this_monday_str}' - INTERVAL 3 WEEK
            ),
            WeeklySnapshot AS (
                -- 2. [ìŠ¤ëƒ…ìƒ·] ì£¼ì°¨ë³„ ìœ ì €ë“¤ì˜ ìµœì¢… ìƒíƒœ
                SELECT 
                    w.week_start,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY w.week_start, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past4Weeks w
                LEFT JOIN user_npti u
                    ON u.updated_at < w.week_start + INTERVAL 1 WEEK
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM-DD ~ YYYY-MM-DD' í˜•íƒœë¡œ ë³€í™˜
                CONCAT(P.week_start, '\n~ ', DATE_ADD(P.week_start, INTERVAL 6 DAY)) AS date_period,

                -- 4. ìœ íš¨í•œ ë°ì´í„°(rn=1)ê°€ ìˆì„ ë•Œë§Œ ì¹´ìš´íŠ¸, ì—†ìœ¼ë©´ 0
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'S' THEN 1 END) AS S_count,

                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'T' THEN 1 END) AS T_count,

                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'F' THEN 1 END) AS F_count,

                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'N' THEN 1 END) AS N_count

            FROM Past4Weeks P -- [í•µì‹¬] ê¸°ì¤€ì´ ë˜ëŠ” íƒ€ì„ë¼ì¸ì„ ë¨¼ì € ë‘¡ë‹ˆë‹¤.
            LEFT JOIN WeeklySnapshot S
                ON P.week_start = S.week_start
            LEFT JOIN npti_code C 
                ON S.npti_code = C.npti_code
            GROUP BY P.week_start
            ORDER BY P.week_start ASC;
        """)

        result4_2 = rows_to_dict(db.execute(sql4_2).fetchall())
        print('result4_2 (ìµœê·¼ 4ì£¼ ì„±í–¥ ìƒì„¸ - 0í¬í•¨) ì™„ë£Œ')

        # 4-3) ì›”ë³„ (ëˆ„ì  ê¸°ì¤€)
        sql4_3 = text(f"""
            WITH RECURSIVE Past6Months AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 6ê°œì›” 'ë§¤ì›” 1ì¼' ìƒì„±
                SELECT '{this_month_str}' AS month_start
                UNION ALL
                SELECT month_start - INTERVAL 1 MONTH
                FROM Past6Months
                WHERE month_start > '{this_month_str}' - INTERVAL 5 MONTH
            ),
            MonthlySnapshot AS (
                -- 2. [ìŠ¤ëƒ…ìƒ·] ì›”ë³„ ìœ ì €ë“¤ì˜ ìµœì¢… ìƒíƒœ
                SELECT 
                    m.month_start,
                    u.npti_code,
                    ROW_NUMBER() OVER (
                        PARTITION BY m.month_start, u.user_id 
                        ORDER BY u.updated_at DESC
                    ) as rn
                FROM Past6Months m
                LEFT JOIN user_npti u
                    ON u.updated_at < m.month_start + INTERVAL 1 MONTH
                JOIN user_info ui
                    ON u.user_id = ui.user_id
                WHERE ui.activation = 1 AND ui.admin = 1
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM' í˜•íƒœë¡œ ë³€í™˜
                DATE_FORMAT(P.month_start, '%Y-%m') AS date_period,

                -- 4. ìœ íš¨í•œ ë°ì´í„°(rn=1)ê°€ ìˆì„ ë•Œë§Œ ì¹´ìš´íŠ¸, ì—†ìœ¼ë©´ 0
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN S.rn = 1 AND C.length_type = 'S' THEN 1 END) AS S_count,

                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN S.rn = 1 AND C.article_type = 'T' THEN 1 END) AS T_count,

                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN S.rn = 1 AND C.info_type = 'F' THEN 1 END) AS F_count,

                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN S.rn = 1 AND C.view_type = 'N' THEN 1 END) AS N_count

            FROM Past6Months P -- [í•µì‹¬] ê¸°ì¤€ì´ ë˜ëŠ” íƒ€ì„ë¼ì¸ì„ ë¨¼ì € ë‘¡ë‹ˆë‹¤.
            LEFT JOIN MonthlySnapshot S
                ON P.month_start = S.month_start
            LEFT JOIN npti_code C 
                ON S.npti_code = C.npti_code
            GROUP BY P.month_start
            ORDER BY P.month_start ASC;
        """)

        result4_3 = rows_to_dict(db.execute(sql4_3).fetchall())
        print('result4_3 (ìµœê·¼ 6ê°œì›” ì„±í–¥ ìƒì„¸ - 0í¬í•¨) ì™„ë£Œ')

        time_now = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')

        # =========================================================
        # 5. ìµœì¢… ë¦¬í„´ (JSON)
        # =========================================================
        return {
            "result1_npti_code": result1_1,
            "result1_age": result1_2,
            "result1_gender": result1_3,

            "result2_day": result2_1,
            "result2_week": result2_2,
            "result2_month": result2_3,

            "result3_npti_type": result3,

            "result4_day": result4_1,
            "result4_week": result4_2,
            "result4_month": result4_3,
            "time_now": time_now
        }

    except Exception as e:
        print(f"Error fetching statistics: {e}")
        return JSONResponse(status_code=500, content={"message": "í†µê³„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})


@app.get("/articles_statistics")
def articles_statistics(db: Session = Depends(get_db)):
    try:
        today_str = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d')
        today = datetime.now(timezone(timedelta(hours=9)))
        this_monday = today - timedelta(days=today.weekday())
        this_monday_str = this_monday.strftime('%Y-%m-%d')
        this_month_start = today.replace(day=1)
        this_month_str = this_month_start.strftime('%Y-%m-%d')
        print(f'ë°ì´í„° ì¶”ì¶œ ì‹œì‘')

        # [Helper í•¨ìˆ˜] DB ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        def rows_to_dict(result_proxy):
            return [dict(row._asdict()) for row in result_proxy]

        # [Helper í•¨ìˆ˜] ë‹¨ì¼ í–‰(1 row) ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        def row_to_dict(row):
            return dict(row._asdict()) if row else {}

        start_date = today - timedelta(days=6)
        start_date_str = start_date.strftime('%Y-%m-%d')
        TARGET_KEYS = ["ì •ì¹˜", "ê²½ì œ", "ì‚¬íšŒ", "ìƒí™œ/ë¬¸í™”", "IT/ê³¼í•™", "ì„¸ê³„", "ìŠ¤í¬ì¸ ", "ì—°ì˜ˆ", "ì§€ì—­"]

        # 1. categoryë³„ ìˆ˜ì§‘ ê¸°ì‚¬ ì¶”ì´(es)
        # 1-1) í•„ë“œ : ì¼
        query1_1 = {
            "size": 0,
            "runtime_mappings": {
                "category_runtime": {
                    "type": "keyword",
                    "script": {
                        # _sourceì—ì„œ ê°’ì„ êº¼ë‚´ì™€ ì„ì‹œ keyword í•„ë“œë¡œ ë§Œë“¦
                        "source": "if (params['_source'].containsKey('category')) { emit(params['_source']['category'].toString()) }"
                    }
                }
            },
            "query": {
                "range": {
                    "pubdate": {
                        "gte": start_date_str,
                        "lte": today_str,
                        "format": "yyyy-MM-dd"
                    }
                }
            },
            "aggs": {
                "per_day": {
                    "date_histogram": {
                        "field": "pubdate",
                        "calendar_interval": "day",
                        "format": "yyyy-MM-dd",
                        "min_doc_count": 0,
                        "extended_bounds": {
                            "min": start_date_str,
                            "max": today_str
                        }
                    },
                    "aggs": {
                        "by_category": {
                            "terms": {
                                # ìœ„ì—ì„œ ì •ì˜í•œ runtime í•„ë“œë¥¼ ì‚¬ìš©
                                "field": "category_runtime",
                                "size": 100,
                                "min_doc_count": 0
                            }
                        }
                    }
                }
            }
        }

        # 3. ê²€ìƒ‰ í•¨ìˆ˜ ì‹¤í–‰
        response = search_news_condition(query1_1)

        # 4. [í›„ì²˜ë¦¬] Grid ìƒì„± (7ì¼ x 16ê°œ ì½”ë“œ = 0ê°’ ì±„ìš°ê¸°)
        result1_1 = []

        if response:
            # ES ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ê¸° í¸í•œ Map í˜•íƒœë¡œ ë³€í™˜
            # êµ¬ì¡°: {'2026-01-08': {'ISTJ': 5}, ...}
            daily_buckets = response['aggregations']['per_day']['buckets']
            data_map = {}

            for day_bucket in daily_buckets:
                d_key = day_bucket['key_as_string']
                cat_map = {}
                for cat_bucket in day_bucket['by_category']['buckets']:
                    cat_map[cat_bucket['key']] = cat_bucket['doc_count']
                data_map[d_key] = cat_map

            # 7ì¼ ë‚ ì§œ ìˆœíšŒ
            for i in range(7):
                # 6ì¼ ì „ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ë‚ ì§œ ìƒì„±
                calc_date = today - timedelta(days=6 - i)
                date_key = calc_date.strftime('%Y-%m-%d')

                # 16ê°œ ì½”ë“œ ìˆœíšŒ
                for key in TARGET_KEYS:
                    # ë°ì´í„°ê°€ ìˆìœ¼ë©´ count, ì—†ìœ¼ë©´ 0
                    count = data_map.get(date_key, {}).get(key, 0)

                    result1_1.append({
                        "date_period": date_key,
                        "category": key,  # category ê°’ì„ npti_codeë¡œ ë§¤í•‘
                        "count": count
                    })

            # ê²°ê³¼ í™•ì¸
            print('ES result (ìµœê·¼ 7ì¼ NPTI codeë³„ ì§‘ê³„ - 0í¬í•¨) ì™„ë£Œ')
        else:
            print("ES Search Failed")

        # 1-2) í•„ë“œ : ì£¼
        week_npti_start_date = this_monday - timedelta(weeks=3)
        week_npti_start_str = week_npti_start_date.strftime('%Y-%m-%d')

        query1_2 = {
            "size": 0,
            "runtime_mappings": {
                "category_runtime": {
                    "type": "keyword",
                    "script": {
                        "source": "if (params['_source'].containsKey('category')) { emit(params['_source']['category'].toString()) }"
                    }
                }
            },
            "query": {
                "range": {
                    "pubdate": {
                        "gte": week_npti_start_str,
                        "lte": today_str,
                        "format": "yyyy-MM-dd"
                    }
                }
            },
            "aggs": {
                "per_week": {
                    "date_histogram": {
                        "field": "pubdate",
                        "calendar_interval": "week",
                        "format": "yyyy-MM-dd",
                        "min_doc_count": 0,
                        "extended_bounds": {
                            "min": week_npti_start_str,
                            "max": today_str
                        }
                    },
                    "aggs": {
                        "by_category": {
                            "terms": {
                                "field": "category_runtime",
                                "size": 100,
                                "min_doc_count": 0
                            }
                        }
                    }
                }
            }
        }

        # 4. ê²€ìƒ‰ ì‹¤í–‰
        # ë³€ìˆ˜ëª… ë³€ê²½: response -> es_resp_week_npti
        es_resp_week_npti = search_news_condition(query1_2)

        # 5. [í›„ì²˜ë¦¬] Grid ìƒì„±
        # ë³€ìˆ˜ëª… ë³€ê²½: final_result -> result_week_npti_list
        result1_2 = []

        if es_resp_week_npti:
            # ES ê²°ê³¼ ë§¤í•‘ìš© ë”•ì…”ë„ˆë¦¬
            # ë³€ìˆ˜ëª… ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ë‚´ë¶€ ë³€ìˆ˜ë„ ìœ ë‹ˆí¬í•˜ê²Œ ì‚¬ìš©
            week_buckets = es_resp_week_npti['aggregations']['per_week']['buckets']
            week_data_map = {}

            for _bucket in week_buckets:
                _d_key = _bucket['key_as_string']
                _cat_map = {}
                for _c_bucket in _bucket['by_category']['buckets']:
                    _cat_map[_c_bucket['key']] = _c_bucket['doc_count']
                week_data_map[_d_key] = _cat_map

            # 4ì£¼ì¹˜ ìˆœíšŒ (3ì£¼ì „ -> 2ì£¼ì „ -> 1ì£¼ì „ -> ì´ë²ˆì£¼)
            for _i in range(3, -1, -1):
                _w_start = this_monday - timedelta(weeks=_i)
                _w_start_str = _w_start.strftime('%Y-%m-%d')
                _w_end = _w_start + timedelta(days=6)

                # ê¸°ê°„ ë¬¸ìì—´ ìƒì„±
                _period_str = f"{_w_start_str}\n~ {_w_end.strftime('%Y-%m-%d')}"

                # 16ê°œ ì½”ë“œ ìˆœíšŒ
                for _code in TARGET_KEYS:
                    # ì•ˆì „í•˜ê²Œ ê°’ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ 0)
                    _cnt = week_data_map.get(_w_start_str, {}).get(_code, 0)

                    result1_2.append({
                        "date_period": _period_str,
                        "category": _code,
                        "count": _cnt
                    })
            # ê²°ê³¼ í™•ì¸
            print('result_week_npti_list (ìµœê·¼ 4ì£¼ NPTI codeë³„ ì§‘ê³„ - 0í¬í•¨) ì™„ë£Œ')
        else:
            print("ES Search Failed (Week NPTI)")

        # 1-3) í•„ë“œ : ì›”
        _y, _m = this_month_start.year, this_month_start.month
        _m -= 5
        while _m <= 0:
            _y -= 1
            _m += 12
        month_npti_start_date = this_month_start.replace(year=_y, month=_m, day=1)
        month_npti_start_str = month_npti_start_date.strftime('%Y-%m-%d')
        month_bounds_str = month_npti_start_date.strftime('%Y-%m')
        today_bounds_str = today.strftime('%Y-%m')

        query1_3 = {
            "size": 0,
            "runtime_mappings": {
                "category_runtime": {
                    "type": "keyword",
                    "script": {
                        # _sourceì—ì„œ category ê°’ì„ êº¼ë‚´ ì„ì‹œ keyword í•„ë“œë¡œ ë³€í™˜
                        "source": "if (params['_source'].containsKey('category')) { emit(params['_source']['category'].toString()) }"
                    }
                }
            },
            "query": {
                "range": {
                    "pubdate": {
                        "gte": month_npti_start_str,
                        "lte": today_str,
                        "format": "yyyy-MM-dd"
                    }
                }
            },
            "aggs": {
                "per_month": {
                    "date_histogram": {
                        "field": "pubdate",
                        "calendar_interval": "month",
                        "format": "yyyy-MM",
                        "min_doc_count": 0,
                        # 6ê°œì›”ì¹˜ ë²„í‚· ê°•ì œ ìƒì„±
                        "extended_bounds": {
                            "min": month_bounds_str,
                            "max": today_bounds_str
                        }
                    },
                    "aggs": {
                        "by_category": {
                            "terms": {
                                "field": "category_runtime",
                                "size": 100,
                                "min_doc_count": 0
                            }
                        }
                    }
                }
            }
        }

        # 4. ê²€ìƒ‰ ì‹¤í–‰ (ë³€ìˆ˜ëª… êµ¬ë¶„)
        es_resp_month_npti = search_news_condition(query1_3)

        # 5. [í›„ì²˜ë¦¬] Grid ìƒì„± (6ê°œì›” x 16ê°œ ì½”ë“œ = 0ê°’ ì±„ìš°ê¸°)
        result1_3 = []

        if es_resp_month_npti:
            # 5-1. ES ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ê¸° í¸í•œ Map í˜•íƒœë¡œ ë³€í™˜
            _month_buckets = es_resp_month_npti['aggregations']['per_month']['buckets']
            _month_data_map = {}

            for _bucket in _month_buckets:
                _d_key = _bucket['key_as_string']  # "YYYY-MM" í˜•íƒœ
                _cat_map = {}
                for _c_bucket in _bucket['by_category']['buckets']:
                    _cat_map[_c_bucket['key']] = _c_bucket['doc_count']
                _month_data_map[_d_key] = _cat_map

            # 5-2. 6ê°œì›”ì¹˜ ë‚ ì§œ ìˆœíšŒ (5ë‹¬ ì „ ~ ì´ë²ˆ ë‹¬)
            for _i in range(5, -1, -1):
                # ë‚ ì§œ ê³„ì‚° (ì—­ìˆœìœ¼ë¡œ ì›” ë¹¼ê¸°)
                _cy, _cm = this_month_start.year, this_month_start.month
                _cm -= _i
                while _cm <= 0:
                    _cy -= 1
                    _cm += 12
                _target_month_date = this_month_start.replace(year=_cy, month=_cm, day=1)
                _date_key = _target_month_date.strftime('%Y-%m')  # Key: YYYY-MM

                # 16ê°œ ì½”ë“œ ìˆœíšŒ
                for _code in TARGET_KEYS:
                    # ì•ˆì „í•˜ê²Œ ê°’ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ 0)
                    _cnt = _month_data_map.get(_date_key, {}).get(_code, 0)

                    result1_3.append({
                        "date_period": _date_key,
                        "category": _code,
                        "count": _cnt
                    })
            # ê²°ê³¼ í™•ì¸
            print('result_month_npti_list (ìµœê·¼ 6ê°œì›” NPTI codeë³„ ì§‘ê³„ - 0í¬í•¨) ì™„ë£Œ')
        else:
            print("ES Search Failed (Month NPTI)")

        # 2. NPTIë³„ ìˆ˜ì§‘ ê¸°ì‚¬ ì¶”ì´ - linear graph
        # 2-1) í•„ë“œ : ì¼
        sql2_1 = text(f"""
            WITH RECURSIVE Past7Days AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 7ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{today_str}' - INTERVAL 6 DAY AS date_period
                UNION ALL
                SELECT date_period + INTERVAL 1 DAY
                FROM Past7Days
                WHERE date_period < '{today_str}'
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] npti_code í…Œì´ë¸”ì—ì„œ ëª¨ë“  ì½”ë“œ(16ê°œ) ê°€ì ¸ì˜¤ê¸°
                SELECT npti_code FROM npti_code
            ),
            DateCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (7ì¼) x (16ê°œ ì½”ë“œ) = 112ê°œ í–‰ ìƒì„±
                -- ê¸°ì‚¬ê°€ í•œ ê±´ë„ ì—†ëŠ” ë‚ ì´ë‚˜ ì½”ë“œë¼ë„ ì´ ë¼ˆëŒ€ëŠ” ë¬´ì¡°ê±´ ì¡´ì¬í•¨
                SELECT d.date_period, c.npti_code
                FROM Past7Days d
                CROSS JOIN AllNPTICodes c
            )
            SELECT 
                G.date_period,
                G.npti_code,
                -- 5. ì‹¤ì œ ê¸°ì‚¬ ë°ì´í„° ì¹´ìš´íŠ¸ (ì—†ìœ¼ë©´ 0)
                COUNT(A.news_id) as article_count
            FROM DateCodeGrid G
            LEFT JOIN articles_npti A
                -- 4. [ë°ì´í„° ë§¤í•‘] ê·¸ë¦¬ë“œì— ì‹¤ì œ ê¸°ì‚¬ ì¡°ì¸
                ON G.npti_code = A.npti_code
                AND A.updated_at >= G.date_period 
                AND A.updated_at < G.date_period + INTERVAL 1 DAY
            GROUP BY G.date_period, G.npti_code
            ORDER BY G.date_period ASC, G.npti_code ASC;
        """)
        result2_1 = rows_to_dict(db.execute(sql2_1).fetchall())
        print('result_articles (ìµœê·¼ 7ì¼ ê¸°ì‚¬ ìˆ˜ì§‘ í˜„í™© - 0í¬í•¨) ì™„ë£Œ')

        # 2-2) í•„ë“œ : ì£¼
        # 1. ì¿¼ë¦¬ ì‘ì„±
        sql_articles_week = text(f"""
            WITH RECURSIVE Past4Weeks AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 4ì£¼(ì´ë²ˆ ì£¼ í¬í•¨)ì˜ ì›”ìš”ì¼ ìƒì„±
                SELECT '{this_monday_str}' AS week_start
                UNION ALL
                SELECT week_start - INTERVAL 1 WEEK
                FROM Past4Weeks
                WHERE week_start > '{this_monday_str}' - INTERVAL 3 WEEK
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] 16ê°œ NPTI ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
                SELECT npti_code FROM npti_code
            ),
            WeekCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (4ì£¼) x (16ê°œ ì½”ë“œ) = 64ê°œ í–‰
                -- ë°ì´í„° ìœ ë¬´ì™€ ìƒê´€ì—†ì´ ë¬´ì¡°ê±´ ì¡´ì¬í•˜ëŠ” ë¼ˆëŒ€
                SELECT w.week_start, c.npti_code
                FROM Past4Weeks w
                CROSS JOIN AllNPTICodes c
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM-DD ~ YYYY-MM-DD' í˜•íƒœë¡œ ë³€í™˜ (ì˜ˆ: 2026-01-05 ~ 2026-01-11)
                CONCAT(G.week_start, '\n~ ', DATE_ADD(G.week_start, INTERVAL 6 DAY)) AS date_period,
    
                G.npti_code,
    
                -- 5. ì‹¤ì œ ê¸°ì‚¬ ë§¤í•‘ ì¹´ìš´íŠ¸ (ì—†ìœ¼ë©´ 0)
                COUNT(A.news_id) as article_count
            FROM WeekCodeGrid G
            LEFT JOIN articles_npti A
                -- 4. [ë°ì´í„° ë§¤í•‘] í•´ë‹¹ ì£¼ì°¨ ê¸°ê°„ ë‚´ì— ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì¡°ì¸
                ON G.npti_code = A.npti_code
                AND A.updated_at >= G.week_start 
                AND A.updated_at < G.week_start + INTERVAL 1 WEEK
            GROUP BY G.week_start, G.npti_code
            ORDER BY G.week_start ASC, G.npti_code ASC;
        """)
        result2_2 = rows_to_dict(db.execute(sql_articles_week).fetchall())
        print('result_articles_week (ìµœê·¼ 4ì£¼ ê¸°ì‚¬ ìˆ˜ì§‘ í˜„í™© - 0í¬í•¨) ì™„ë£Œ')

        # 2-3) í•„ë“œ : ì›”
        # 1. ì¿¼ë¦¬ ì‘ì„±
        sql2_3 = text(f"""
            WITH RECURSIVE Past6Months AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 6ê°œì›”(ì´ë²ˆ ë‹¬ í¬í•¨) 'ë§¤ì›” 1ì¼' ìƒì„±
                SELECT '{this_month_str}' AS month_start
                UNION ALL
                SELECT month_start - INTERVAL 1 MONTH
                FROM Past6Months
                WHERE month_start > '{this_month_str}' - INTERVAL 5 MONTH
            ),
            AllNPTICodes AS (
                -- 2. [ì½”ë“œ ëª©ë¡] 16ê°œ NPTI ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
                SELECT npti_code FROM npti_code
            ),
            MonthCodeGrid AS (
                -- 3. [ê·¸ë¦¬ë“œ ìƒì„±] (6ê°œì›”) x (16ê°œ ì½”ë“œ) = 96ê°œ í–‰
                -- ë°ì´í„° ìœ ë¬´ì™€ ìƒê´€ì—†ì´ ë¬´ì¡°ê±´ ì¡´ì¬í•˜ëŠ” ë¼ˆëŒ€
                SELECT m.month_start, c.npti_code
                FROM Past6Months m
                CROSS JOIN AllNPTICodes c
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM' í˜•íƒœë¡œ ë³€í™˜ (ì˜ˆ: 2025-08)
                DATE_FORMAT(G.month_start, '%Y-%m') AS date_period,
    
                G.npti_code,
    
                -- 5. ì‹¤ì œ ê¸°ì‚¬ ë§¤í•‘ ì¹´ìš´íŠ¸ (ì—†ìœ¼ë©´ 0)
                COUNT(A.news_id) as article_count
            FROM MonthCodeGrid G
            LEFT JOIN articles_npti A
                -- 4. [ë°ì´í„° ë§¤í•‘] í•´ë‹¹ ì›” ê¸°ê°„ ë‚´ì— ìˆ˜ì§‘ëœ ê¸°ì‚¬ ì¡°ì¸
                -- (í•´ë‹¹ ì›” 1ì¼ 0ì‹œ ~ ë‹¤ìŒ ë‹¬ 1ì¼ 0ì‹œ ì „ê¹Œì§€)
                ON G.npti_code = A.npti_code
                AND A.updated_at >= G.month_start 
                AND A.updated_at < G.month_start + INTERVAL 1 MONTH
            GROUP BY G.month_start, G.npti_code
            ORDER BY G.month_start ASC, G.npti_code ASC;
        """)
        result2_3 = rows_to_dict(db.execute(sql2_3).fetchall())
        print('result_articles_month (ìµœê·¼ 6ê°œì›” ê¸°ì‚¬ ìˆ˜ì§‘ í˜„í™© - 0í¬í•¨) ì™„ë£Œ')

        # 3. NPTI ê¸°ì¤€ë³„ ìˆ˜ì§‘ ê¸°ì‚¬ ì¶”ì´ - bar chart
        # 3-1) í•„ë“œ : ì¼
        # 1. ì¿¼ë¦¬ ì‘ì„±
        sql3_1 = text(f"""
            WITH RECURSIVE Past7Days AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 7ì¼ ë‚ ì§œ ìƒì„±
                SELECT '{today_str}' - INTERVAL 6 DAY AS date_period
                UNION ALL
                SELECT date_period + INTERVAL 1 DAY
                FROM Past7Days
                WHERE date_period < '{today_str}'
            ),
            DailyArticles AS (
                -- 2. [ë°ì´í„° ë§¤í•‘] íƒ€ì„ë¼ì¸(P)ì„ ê¸°ì¤€ìœ¼ë¡œ 'í•´ë‹¹ ì¼'ì— ìˆ˜ì§‘ëœ ê¸°ì‚¬ë§Œ ë§¤í•‘
                -- (ëˆ„ì  ì•„ë‹˜: updated_atì´ í•´ë‹¹ ì¼ 00ì‹œ ~ ë‹¤ìŒë‚  00ì‹œ ì „ê¹Œì§€)
                SELECT 
                    P.date_period,
                    A.length_type,
                    A.article_type,
                    A.info_type,
                    A.view_type
                FROM Past7Days P
                LEFT JOIN articles_npti A
                    ON A.updated_at >= P.date_period 
                    AND A.updated_at < P.date_period + INTERVAL 1 DAY
            )
            SELECT 
                -- ë‚ ì§œ ê·¸ëŒ€ë¡œ ì¶œë ¥ (YYYY-MM-DD)
                date_period,
    
                -- 3. 8ê°€ì§€ ì†ì„±ë³„ ì¹´ìš´íŠ¸ ì§‘ê³„ (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0)
                COUNT(CASE WHEN length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN length_type = 'S' THEN 1 END) AS S_count,
    
                COUNT(CASE WHEN article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN article_type = 'T' THEN 1 END) AS T_count,
    
                COUNT(CASE WHEN info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN info_type = 'F' THEN 1 END) AS F_count,
    
                COUNT(CASE WHEN view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN view_type = 'N' THEN 1 END) AS N_count
    
            FROM DailyArticles
            GROUP BY date_period
            ORDER BY date_period ASC;
        """)
        result3_1 = rows_to_dict(db.execute(sql3_1).fetchall())
        print('result_articles_type_day (ìµœê·¼ 7ì¼ ê¸°ì‚¬ ì„±í–¥ ìƒì„¸ - 0í¬í•¨) ì™„ë£Œ')


        # 3-2) í•„ë“œ : ì£¼
        # 1. ì¿¼ë¦¬ ì‘ì„±
        sql3_2 = text(f"""
            WITH RECURSIVE Past4Weeks AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 4ì£¼(ì´ë²ˆ ì£¼ í¬í•¨)ì˜ ì›”ìš”ì¼ ìƒì„±
                SELECT '{this_monday_str}' AS week_start
                UNION ALL
                SELECT week_start - INTERVAL 1 WEEK
                FROM Past4Weeks
                WHERE week_start > '{this_monday_str}' - INTERVAL 3 WEEK
            ),
            WeeklyArticles AS (
                -- 2. [ë°ì´í„° ë§¤í•‘] íƒ€ì„ë¼ì¸(P)ì„ ê¸°ì¤€ìœ¼ë¡œ 'í•´ë‹¹ ì£¼'ì— ìˆ˜ì§‘ëœ ê¸°ì‚¬ë§Œ ë§¤í•‘
                -- (ëˆ„ì  ì•„ë‹˜: updated_atì´ í•´ë‹¹ ì£¼ ì›”~ì¼ ë²”ìœ„ ë‚´ì— ìˆëŠ” ê²ƒë§Œ)
                SELECT 
                    P.week_start,
                    A.length_type,
                    A.article_type,
                    A.info_type,
                    A.view_type
                FROM Past4Weeks P
                LEFT JOIN articles_npti A
                    ON A.updated_at >= P.week_start 
                    AND A.updated_at < P.week_start + INTERVAL 1 WEEK
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM-DD ~ YYYY-MM-DD' í˜•íƒœë¡œ ë³€í™˜ (ì˜ˆ: 2026-01-05 ~ 2026-01-11)
                CONCAT(week_start, '\n~ ', DATE_ADD(week_start, INTERVAL 6 DAY)) AS date_period,
    
                -- 3. 8ê°€ì§€ ì†ì„±ë³„ ì¹´ìš´íŠ¸ ì§‘ê³„ (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0)
                COUNT(CASE WHEN length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN length_type = 'S' THEN 1 END) AS S_count,
    
                COUNT(CASE WHEN article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN article_type = 'T' THEN 1 END) AS T_count,
    
                COUNT(CASE WHEN info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN info_type = 'F' THEN 1 END) AS F_count,
    
                COUNT(CASE WHEN view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN view_type = 'N' THEN 1 END) AS N_count
    
            FROM WeeklyArticles
            GROUP BY week_start
            ORDER BY week_start ASC;
        """)
        result3_2 = rows_to_dict(db.execute(sql3_2).fetchall())
        print('result_articles_type_week (ìµœê·¼ 4ì£¼ ê¸°ì‚¬ ì„±í–¥ ìƒì„¸ - 0í¬í•¨) ì™„ë£Œ')


        # 3-3) í•„ë“œ : ì›”
        sql3_3 = text(f"""
            WITH RECURSIVE Past6Months AS (
                -- 1. [íƒ€ì„ë¼ì¸] ìµœê·¼ 6ê°œì›”(ì´ë²ˆ ë‹¬ í¬í•¨) 'ë§¤ì›” 1ì¼' ìƒì„±
                SELECT '{this_month_str}' AS month_start
                UNION ALL
                SELECT month_start - INTERVAL 1 MONTH
                FROM Past6Months
                WHERE month_start > '{this_month_str}' - INTERVAL 5 MONTH
            ),
            MonthlyArticles AS (
                -- 2. [ë°ì´í„° ë§¤í•‘] íƒ€ì„ë¼ì¸(P)ì„ ê¸°ì¤€ìœ¼ë¡œ í•´ë‹¹ ì›”ì— ì‘ì„±ëœ ê¸°ì‚¬(A)ë¥¼ ë¶™ì„
                SELECT 
                    P.month_start,
                    A.length_type,
                    A.article_type,
                    A.info_type,
                    A.view_type
                FROM Past6Months P
                LEFT JOIN articles_npti A
                    ON A.updated_at >= P.month_start 
                    AND A.updated_at < P.month_start + INTERVAL 1 MONTH
            )
            SELECT 
                -- ë‚ ì§œë¥¼ 'YYYY-MM' í˜•íƒœë¡œ ë³€í™˜
                DATE_FORMAT(month_start, '%Y-%m') AS date_period,
    
                -- 3. 8ê°€ì§€ ì†ì„±ë³„ ì¹´ìš´íŠ¸ ì§‘ê³„ (ë°ì´í„° ì—†ìœ¼ë©´ 0)
                COUNT(CASE WHEN length_type = 'L' THEN 1 END) AS L_count,
                COUNT(CASE WHEN length_type = 'S' THEN 1 END) AS S_count,
    
                COUNT(CASE WHEN article_type = 'C' THEN 1 END) AS C_count,
                COUNT(CASE WHEN article_type = 'T' THEN 1 END) AS T_count,
    
                COUNT(CASE WHEN info_type = 'I' THEN 1 END) AS I_count,
                COUNT(CASE WHEN info_type = 'F' THEN 1 END) AS F_count,
    
                COUNT(CASE WHEN view_type = 'P' THEN 1 END) AS P_count,
                COUNT(CASE WHEN view_type = 'N' THEN 1 END) AS N_count
    
            FROM MonthlyArticles
            GROUP BY month_start
            ORDER BY month_start ASC;
        """)
        result3_3 = rows_to_dict(db.execute(sql3_3).fetchall())
        print('result_articles_type_month (ìµœê·¼ 6ê°œì›” ê¸°ì‚¬ ì„±í–¥ ìƒì„¸ - 0í¬í•¨) ì™„ë£Œ')
        time_now = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')

        return {
            "result1_day": result1_1,
            "result1_week": result1_2,
            "result1_month": result1_3,

            "result2_day": result2_1,
            "result2_week": result2_2,
            "result2_month": result2_3,

            "result3_day": result3_1,
            "result3_week": result3_2,
            "result3_month": result3_3,
            "time_now": time_now
        }
    except Exception as e:
        print(f'Error ë°œìƒ : {e}')
        return JSONResponse(status_code=500, content = {"msg":"ê¸°ì‚¬ í†µê³„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})